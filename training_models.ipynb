{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_DAY_WINDOW = 10\n",
    "LEN_DAY_TARGET = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_adjacent(dates):\n",
    "    for i in range(len(dates) - 1):\n",
    "        date1 = dates[i]\n",
    "        date2 = dates[i+1]\n",
    "\n",
    "        date1_obj = datetime.strptime(date1, '%Y-%m-%d')\n",
    "        date2_obj = datetime.strptime(date2, '%Y-%m-%d')\n",
    "\n",
    "        date_diff = abs((date1_obj - date2_obj).days)\n",
    "\n",
    "        if date_diff > 1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_features(weather_data_path = \"data/weather_data.csv\"):\n",
    "    weather_data = pd.read_csv(weather_data_path)\n",
    "    weather_data.drop(['Unnamed: 0', 'snow', 'wpgt', 'tsun', 'prcp', 'tmin', 'tmax'], axis=1, inplace=True)\n",
    "    weather_data['date'] = pd.to_datetime(weather_data['date'])\n",
    "    weather_data['month_day'] = weather_data['date'].dt.strftime('%m-%d')\n",
    "    weather_data = weather_data.groupby('month_day').mean().reset_index()\n",
    "\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(df, target = 'AMBROSIA', stride = 1, train = True):\n",
    "    df = df.drop(['location', 'Unnamed: 0'], axis = 1)\n",
    "    upper = LEN_DAY_WINDOW + LEN_DAY_TARGET + 1\n",
    "    if not train:\n",
    "       upper = LEN_DAY_WINDOW\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(0, df.shape[0] - (upper - 1), stride):\n",
    "        ran = range(i, i + LEN_DAY_WINDOW)\n",
    "\n",
    "        dates = list(df.iloc[ran]['date'].values)\n",
    "        X.append(np.array(df.iloc[ran]).flatten())\n",
    "        \n",
    "        if train:\n",
    "            y.append((\n",
    "                float(df.iloc[[i+LEN_DAY_WINDOW + 1]][target]),\n",
    "                float(df.iloc[[i+LEN_DAY_WINDOW + 2]][target]),\n",
    "                float(df.iloc[[i+LEN_DAY_WINDOW + 3]][target]),\n",
    "            ))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test(train_path, test_path, stride = 1, target = 'AMBROSIA'):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "\n",
    "    weather_df = get_weather_features()\n",
    "    df_train['month_day'] = pd.to_datetime(df_train['date']).dt.strftime('%m-%d')\n",
    "    df_train = df_train.merge(weather_df, on = 'month_day', how = 'left')\n",
    "    df_train.drop(['month_day'], axis = 1, inplace = True)\n",
    "\n",
    "    df_test['month_day'] = pd.to_datetime(df_test['date']).dt.strftime('%m-%d')\n",
    "    df_test = df_test.merge(weather_df, on = 'month_day', how = 'left')\n",
    "    df_test.drop(['month_day'], axis = 1, inplace = True)\n",
    "\n",
    "    locations = df_train['location'].unique()\n",
    "    batch_id_loc = {}\n",
    "    for loc in locations:\n",
    "        batch_id_loc[loc] = df_test[df_test['location'] == loc]['batch_id'].unique()\n",
    "\n",
    "    df_test = df_test.drop('batch_id', axis = 1)\n",
    "\n",
    "    train_data = {}\n",
    "    train_targets = {}\n",
    "    test_data = {}\n",
    "\n",
    "    for location in locations:\n",
    "        train_data[location] = df_train[df_train['location'] == location]\n",
    "        train_data[location], train_targets[location] = reshape_data(train_data[location], target, stride)\n",
    "        test_data[location] = df_test[df_test['location'] == location]\n",
    "        test_data[location], _ = reshape_data(test_data[location], target = target, stride = LEN_DAY_WINDOW, train = False)\n",
    "\n",
    "    \n",
    "    df_train.drop(['location', 'Unnamed: 0'], axis = 1, inplace = True)\n",
    "    column_names = df_train.columns\n",
    "    \n",
    "    return train_data, train_targets, test_data, batch_id_loc, column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colname_by_index(column_names, index):\n",
    "    return column_names[index % len(column_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_data_location(X_train, X_test, y, location, column_names):\n",
    "    X_train_loc = pd.DataFrame(X_train[location])\n",
    "    y_loc = y[location]\n",
    "    X_test_loc = pd.DataFrame(X_test[location])\n",
    "\n",
    "    X_train_loc.columns = [get_colname_by_index(column_names, i) + \"_\" + str(i // len(column_names)) for i in range(X_train_loc.shape[1])]\n",
    "    X_test_loc.columns = [get_colname_by_index(column_names, i) + \"_\" + str(i // len(column_names)) for i in range(X_test_loc.shape[1])]\n",
    "\n",
    "    return X_train_loc, y_loc, X_test_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_from_prophet(dates):\n",
    "    dataset_path = \"data/\"\n",
    "\n",
    "    with open('models/prophet.json', 'r') as fin:\n",
    "        m = model_from_json(fin.read())  # Load model\n",
    "\n",
    "    future = pd.DataFrame({'ds': dates})\n",
    "    future['floor'] = 0\n",
    "    future['cap'] = 2500\n",
    "\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    ans = []\n",
    "    for forecast_row in forecast.itertuples():\n",
    "        val = int(forecast_row.yhat)\n",
    "        val = max(0, val)\n",
    "        ans.append(val)\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prophet_features(df):\n",
    "    date_columns = []\n",
    "    for i, col in enumerate(df.columns):\n",
    "        if col.startswith('date'): date_columns.append(col)\n",
    "\n",
    "    last_dates = list(df[date_columns[-1]])\n",
    "    last_dates = [datetime.strptime(last_date, '%Y-%m-%d') for last_date in last_dates]\n",
    "\n",
    "    day11 = [last_date + timedelta(days=1) for last_date in last_dates]\n",
    "    day11 = [d.strftime('%Y-%m-%d') for d in day11]\n",
    "\n",
    "    day12 = [last_date + timedelta(days=2) for last_date in last_dates]\n",
    "    day12 = [d.strftime('%Y-%m-%d') for d in day12]\n",
    "\n",
    "    day13 = [last_date + timedelta(days=3) for last_date in last_dates]\n",
    "    day13 = [d.strftime('%Y-%m-%d') for d in day13]\n",
    "\n",
    "    df['prophet_1'] = get_pred_from_prophet(day11)\n",
    "    df['prophet_2'] = get_pred_from_prophet(day12)\n",
    "    df['prophet_3'] = get_pred_from_prophet(day13)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_targets_day(y_loc, day):\n",
    "    y_loc_day = [x[day] for x in y_loc]\n",
    "    \n",
    "    return y_loc_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_16372\\3497320344.py:6: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  weather_data = weather_data.groupby('month_day').mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                location        date  ACER  ALNUS  AMBROSIA  \\\n",
      "0         265  БЕОГРАД - НОВИ БЕОГРАД  2016-02-02     0      0         0   \n",
      "1         266  БЕОГРАД - НОВИ БЕОГРАД  2016-02-03     0      1         0   \n",
      "2         267  БЕОГРАД - НОВИ БЕОГРАД  2016-02-04     0      0         0   \n",
      "3         268  БЕОГРАД - НОВИ БЕОГРАД  2016-02-05     0      2         0   \n",
      "4         269  БЕОГРАД - НОВИ БЕОГРАД  2016-02-06     0      0         0   \n",
      "\n",
      "   ARTEMISIA  BETULA  CANNABACEAE  CARPINUS  ...  QUERCUS  RUMEX  SALIX  \\\n",
      "0          0       0            0         0  ...        0      0      0   \n",
      "1          0       0            0         0  ...        0      0      0   \n",
      "2          0       0            0         0  ...        0      0      0   \n",
      "3          0       0            0         0  ...        0      0      0   \n",
      "4          0       0            0         0  ...        0      0      0   \n",
      "\n",
      "   TILIA  ULMACEAE  URTICACEAE      tavg        wdir       wspd         pres  \n",
      "0      0         1           0  7.857778  187.750000  11.780000  1013.657500  \n",
      "1      0         8           0  8.338636  219.575758  11.986486  1013.441026  \n",
      "2      0         1           0  6.125000  226.529412  11.052632  1015.610811  \n",
      "3      0         0           0  4.931818  247.483871  11.327027  1017.530556  \n",
      "4      0         2           0  4.597619  206.100000  11.508333  1020.206061  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data, train_targets, test_data, batch_id, column_names = load_train_test('data/pollen_train.csv', 'data/pollen_test.csv', stride = 1, target = 'AMBROSIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES_DAY = len(column_names)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def predict_three_days(X, X_test, y):\n",
    "    model11 = xgb.XGBRegressor()\n",
    "    model11.fit(X, return_targets_day(y, 0))\n",
    "    day11 = model11.predict(X)\n",
    "    day11[day11 < 0] = 0\n",
    "    day11 = day11.astype(int)\n",
    "    yhat1 = model11.predict(X_test)\n",
    "\n",
    "    error = np.mean(np.abs(cross_val_score(model11, X, y, cv=5, scoring='neg_mean_absolute_error')))\n",
    "    print(\"MAE: \", error)\n",
    "\n",
    "    X = X.iloc[:, N_FEATURES_DAY:]\n",
    "    X['day11'] = day11\n",
    "\n",
    "    X_test = X_test.iloc[:, N_FEATURES_DAY:]\n",
    "    X_test['day11'] = yhat1\n",
    "\n",
    "    model12 = xgb.XGBRegressor()\n",
    "    model12.fit(X, return_targets_day(y, 1))\n",
    "    day12 = model12.predict(X)\n",
    "    day12[day12 < 0] = 0\n",
    "    day12 = day12.astype(int)\n",
    "    yhat2 = model12.predict(X_test)\n",
    "\n",
    "    X = X.iloc[:, N_FEATURES_DAY:]\n",
    "    X['day12'] = day12\n",
    "\n",
    "    X_test = X_test.iloc[:, N_FEATURES_DAY:]\n",
    "    X_test['day12'] = yhat2\n",
    "\n",
    "    model13 = xgb.XGBRegressor()\n",
    "    model13.fit(X, return_targets_day(y, 2))\n",
    "    day13 = model13.predict(X)\n",
    "    day13[day13 < 0] = 0\n",
    "    day13 = day13.astype(int)\n",
    "    yhat3 = model13.predict(X_test)\n",
    "\n",
    "\n",
    "    yhat1[yhat1 < 0] = 0\n",
    "    yhat1 = yhat1.astype(int)\n",
    "    yhat2[yhat2 < 0] = 0\n",
    "    yhat2 = yhat2.astype(int)\n",
    "    yhat3[yhat3 < 0] = 0\n",
    "    yhat3 = yhat3.astype(int)\n",
    "\n",
    "    return yhat1, yhat2, yhat3, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_dates(df, keep_date=False):\n",
    "    date_columns = []\n",
    "    for i, col in enumerate(df.columns):\n",
    "        if col.startswith('date'): date_columns.append(col)\n",
    "    \n",
    "    if keep_date:\n",
    "        for col in date_columns:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "            df['day'] = df[col].dt.day\n",
    "            df['month'] = df[col].dt.month\n",
    "            df['year'] = df[col].dt.year - 2017\n",
    "            df.drop([col], axis=1, inplace=True)\n",
    "    else:\n",
    "        for col in date_columns:\n",
    "            df.drop([col], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locations(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    locations = df_train['location'].unique()\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location:  БЕОГРАД - НОВИ БЕОГРАД\n",
      "MAE:  17.541888408330298\n",
      "Location:  ВРШАЦ\n",
      "MAE:  18.523563378927655\n",
      "Location:  КРАГУЈЕВАЦ\n",
      "MAE:  9.976562112993864\n",
      "Location:  КРАЉЕВО\n",
      "MAE:  9.417293545131836\n",
      "Location:  НИШ\n",
      "MAE:  4.958351522078163\n",
      "Location:  ПОЖАРЕВАЦ\n",
      "MAE:  15.803620694258328\n",
      "Location:  СУБОТИЦА\n",
      "MAE:  26.470173451223427\n",
      "Mean error:  14.670207587563366\n"
     ]
    }
   ],
   "source": [
    "locations = get_locations('data/pollen_train.csv')\n",
    "\n",
    "res = {}\n",
    "batch_for_df = {}\n",
    "errors = []\n",
    "\n",
    "for loc in locations:\n",
    "    print(\"Location: \", loc)\n",
    "    X_loc, y_loc, X_test_loc = return_data_location(train_data, test_data, train_targets, loc, column_names)\n",
    "    X_loc = add_prophet_features(X_loc)\n",
    "\n",
    "    X_test_loc = add_prophet_features(X_test_loc)\n",
    "\n",
    "    X_loc = handle_dates(X_loc, keep_date=True)\n",
    "    X_test_loc = handle_dates(X_test_loc, keep_date=True)\n",
    "    \n",
    "    yhat1_loc, yhat2_loc, yhat3_loc, err = predict_three_days(X_loc, X_test_loc, y_loc)\n",
    "\n",
    "    errors.append(err)\n",
    "\n",
    "    bid = batch_id[loc]\n",
    "    for i, b in enumerate(bid):\n",
    "        batch_for_df[b] = [yhat1_loc[i], yhat2_loc[i], yhat3_loc[i]]\n",
    "print(\"Mean error: \", np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(batch_for_df).T\n",
    "res_df.head()\n",
    "res_df.sort_index(inplace=True)\n",
    "res_df.columns = ['1 day prediction','2 days prediction','3 days prediction']\n",
    "res_df.insert(0, 'batch_id', range(1, res_df.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('results/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
