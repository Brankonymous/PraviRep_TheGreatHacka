{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_DAY_WINDOW = 10\n",
    "LEN_DAY_TARGET = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_adjacent(dates):\n",
    "    for i in range(len(dates) - 1):\n",
    "        date1 = dates[i]\n",
    "        date2 = dates[i+1]\n",
    "\n",
    "        date1_obj = datetime.strptime(date1, '%Y-%m-%d')\n",
    "        date2_obj = datetime.strptime(date2, '%Y-%m-%d')\n",
    "\n",
    "        date_diff = abs((date1_obj - date2_obj).days)\n",
    "\n",
    "        if date_diff > 1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(df, target = 'AMBROSIA', stride = 1, train = True):\n",
    "    df = df.drop(['location', 'Unnamed: 0'], axis = 1)\n",
    "    upper = LEN_DAY_WINDOW + LEN_DAY_TARGET + 1\n",
    "    if not train:\n",
    "       upper = LEN_DAY_WINDOW\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(0, df.shape[0] - (upper - 1), stride):\n",
    "        ran = range(i, i + LEN_DAY_WINDOW)\n",
    "\n",
    "        dates = list(df.iloc[ran]['date'].values)\n",
    "        #if are_adjacent(dates):\n",
    "        if True:\n",
    "            X.append(np.array(df.iloc[ran]).flatten())\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if train:\n",
    "            y.append((\n",
    "                float(df.iloc[[i+LEN_DAY_WINDOW + 1]][target]),\n",
    "                float(df.iloc[[i+LEN_DAY_WINDOW + 2]][target]),\n",
    "                float(df.iloc[[i+LEN_DAY_WINDOW + 3]][target]),\n",
    "            ))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test(train_path, test_path, stride = 1, target = 'AMBROSIA'):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "\n",
    "    locations = df_train['location'].unique()\n",
    "    batch_id_loc = {}\n",
    "    for loc in locations:\n",
    "        batch_id_loc[loc] = df_test[df_test['location'] == loc]['batch_id'].unique()\n",
    "\n",
    "    df_test = df_test.drop('batch_id', axis = 1)\n",
    "\n",
    "    train_data = {}\n",
    "    train_targets = {}\n",
    "    test_data = {}\n",
    "\n",
    "    for location in locations:\n",
    "        train_data[location] = df_train[df_train['location'] == location]\n",
    "        train_data[location], train_targets[location] = reshape_data(train_data[location], target, stride)\n",
    "        test_data[location] = df_test[df_test['location'] == location]\n",
    "        test_data[location], _ = reshape_data(test_data[location], target = target, stride = LEN_DAY_WINDOW, train = False)\n",
    "\n",
    "    \n",
    "    df_train.drop(['location', 'Unnamed: 0'], axis = 1, inplace = True)\n",
    "    column_names = df_train.columns\n",
    "    \n",
    "    return train_data, train_targets, test_data, batch_id_loc, column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colname_by_index(column_names, index):\n",
    "    return column_names[index % len(column_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_data_location(X_train, X_test, y, location, column_names):\n",
    "    X_train_loc = pd.DataFrame(X_train[location])\n",
    "    y_loc = y[location]\n",
    "    X_test_loc = pd.DataFrame(X_test[location])\n",
    "\n",
    "    X_train_loc.columns = [get_colname_by_index(column_names, i) + \"_\" + str(i // len(column_names)) for i in range(X_train_loc.shape[1])]\n",
    "    X_test_loc.columns = [get_colname_by_index(column_names, i) + \"_\" + str(i // len(column_names)) for i in range(X_test_loc.shape[1])]\n",
    "\n",
    "    return X_train_loc, y_loc, X_test_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_from_prophet(dates):\n",
    "    dataset_path = \"data/\"\n",
    "\n",
    "    with open('models/prophet.json', 'r') as fin:\n",
    "        m = model_from_json(fin.read())  # Load model\n",
    "\n",
    "    future = pd.DataFrame({'ds': dates})\n",
    "    future['floor'] = 0\n",
    "    future['cap'] = 2500\n",
    "\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    ans = []\n",
    "    for forecast_row in forecast.itertuples():\n",
    "        val = int(forecast_row.yhat)\n",
    "        val = max(0, val)\n",
    "        ans.append(val)\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prophet_features(df):\n",
    "    date_columns = []\n",
    "    for i, col in enumerate(df.columns):\n",
    "        if col.startswith('date'): date_columns.append(col)\n",
    "\n",
    "    last_dates = list(df[date_columns[-1]])\n",
    "    last_dates = [datetime.strptime(last_date, '%Y-%m-%d') for last_date in last_dates]\n",
    "\n",
    "    day11 = [last_date + timedelta(days=1) for last_date in last_dates]\n",
    "    day11 = [d.strftime('%Y-%m-%d') for d in day11]\n",
    "\n",
    "    day12 = [last_date + timedelta(days=2) for last_date in last_dates]\n",
    "    day12 = [d.strftime('%Y-%m-%d') for d in day12]\n",
    "\n",
    "    day13 = [last_date + timedelta(days=3) for last_date in last_dates]\n",
    "    day13 = [d.strftime('%Y-%m-%d') for d in day13]\n",
    "\n",
    "    df['prophet_1'] = get_pred_from_prophet(day11)\n",
    "    df['prophet_2'] = get_pred_from_prophet(day12)\n",
    "    df['prophet_3'] = get_pred_from_prophet(day13)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_targets_day(y_loc, day):\n",
    "    y_loc_day = [x[day] for x in y_loc]\n",
    "    \n",
    "    return y_loc_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_targets, test_data, batch_id, column_names = load_train_test('data/pollen_train.csv', 'data/pollen_test.csv', stride = 1, target = 'AMBROSIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES_DAY = len(column_names)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def predict_three_days(X, X_test, y):\n",
    "    model11 = xgb.XGBRegressor(max_depth = 10)\n",
    "    model11.fit(X, return_targets_day(y, 0))\n",
    "    day11 = model11.predict(X)\n",
    "    day11[day11 < 0] = 0\n",
    "    day11 = day11.astype(int)\n",
    "    yhat1 = model11.predict(X_test)\n",
    "\n",
    "    error = np.mean(np.abs(cross_val_score(model11, X, y, cv=5, scoring='neg_mean_absolute_error')))\n",
    "    print(\"MAE: \", error)\n",
    "\n",
    "    X = X.iloc[:, N_FEATURES_DAY:]\n",
    "    X['day11'] = day11\n",
    "\n",
    "    X_test = X_test.iloc[:, N_FEATURES_DAY:]\n",
    "    X_test['day11'] = yhat1\n",
    "\n",
    "    model12 = xgb.XGBRegressor(max_depth = 10)\n",
    "    model12.fit(X, return_targets_day(y, 1))\n",
    "    day12 = model12.predict(X)\n",
    "    day12[day12 < 0] = 0\n",
    "    day12 = day12.astype(int)\n",
    "    yhat2 = model12.predict(X_test)\n",
    "\n",
    "    X = X.iloc[:, N_FEATURES_DAY:]\n",
    "    X['day12'] = day12\n",
    "\n",
    "    X_test = X_test.iloc[:, N_FEATURES_DAY:]\n",
    "    X_test['day12'] = yhat2\n",
    "\n",
    "    model13 = xgb.XGBRegressor(max_depth = 10)\n",
    "    model13.fit(X, return_targets_day(y, 2))\n",
    "    day13 = model13.predict(X)\n",
    "    day13[day13 < 0] = 0\n",
    "    day13 = day13.astype(int)\n",
    "    yhat3 = model13.predict(X_test)\n",
    "\n",
    "\n",
    "    yhat1[yhat1 < 0] = 0\n",
    "    yhat1 = yhat1.astype(int)\n",
    "    yhat2[yhat2 < 0] = 0\n",
    "    yhat2 = yhat2.astype(int)\n",
    "    yhat3[yhat3 < 0] = 0\n",
    "    yhat3 = yhat3.astype(int)\n",
    "\n",
    "    return yhat1, yhat2, yhat3, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_dates(df, keep_date=False):\n",
    "    date_columns = []\n",
    "    for i, col in enumerate(df.columns):\n",
    "        if col.startswith('date'): date_columns.append(col)\n",
    "    \n",
    "    if keep_date:\n",
    "        for col in date_columns:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "            df['day'] = df[col].dt.day\n",
    "            df['month'] = df[col].dt.month\n",
    "            df['year'] = df[col].dt.year - 2017\n",
    "            df.drop([col], axis=1, inplace=True)\n",
    "    else:\n",
    "        for col in date_columns:\n",
    "            df.drop([col], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locations(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    locations = df_train['location'].unique()\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_features(df, weather_data_path = \"data/weather_data.csv\"):\n",
    "    weather_data = pd.read_csv(weather_data_path)\n",
    "    weather_data.drop(['Unnamed: 0', 'snow', 'wpgt', 'tsun', 'prcp', 'tmin', 'tmax'], axis=1, inplace=True)\n",
    "    weather_data['date'] = pd.to_datetime(weather_data['date'])\n",
    "    weather_data['month_day'] = weather_data['date'].dt.strftime('%m-%d')\n",
    "    weather_data = weather_data.groupby('month_day').mean().reset_index()\n",
    "\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location:  БЕОГРАД - НОВИ БЕОГРАД\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DELL\\PycharmProjects\\PraviRep_TheGreatHacka\\training_models_2.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/PycharmProjects/PraviRep_TheGreatHacka/training_models_2.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m X_loc \u001b[39m=\u001b[39m add_prophet_features(X_loc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/PycharmProjects/PraviRep_TheGreatHacka/training_models_2.ipynb#X42sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m X_test_loc \u001b[39m=\u001b[39m add_prophet_features(X_test_loc)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DELL/PycharmProjects/PraviRep_TheGreatHacka/training_models_2.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m X_loc \u001b[39m=\u001b[39m add_weather_features(X_loc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/PycharmProjects/PraviRep_TheGreatHacka/training_models_2.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m X_test_loc \u001b[39m=\u001b[39m add_weather_features(X_test_loc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/PycharmProjects/PraviRep_TheGreatHacka/training_models_2.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m X_loc \u001b[39m=\u001b[39m handle_dates(X_loc, keep_date\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\DELL\\PycharmProjects\\PraviRep_TheGreatHacka\\training_models_2.ipynb Cell 16\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/PycharmProjects/PraviRep_TheGreatHacka/training_models_2.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m weather_data \u001b[39m=\u001b[39m weather_data\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mmonth_day\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/PycharmProjects/PraviRep_TheGreatHacka/training_models_2.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#weather_data.drop(['date'], axis=1, inplace=True)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DELL/PycharmProjects/PraviRep_TheGreatHacka/training_models_2.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mmonth_day\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/PycharmProjects/PraviRep_TheGreatHacka/training_models_2.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mmerge(weather_data, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmonth_day\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/PycharmProjects/PraviRep_TheGreatHacka/training_models_2.ipynb#X42sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mmonth_day\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3804\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3806\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "locations = get_locations('data/pollen_train.csv')\n",
    "\n",
    "res = {}\n",
    "batch_for_df = {}\n",
    "errors = []\n",
    "\n",
    "for loc in locations:\n",
    "    print(\"Location: \", loc)\n",
    "    X_loc, y_loc, X_test_loc = return_data_location(train_data, test_data, train_targets, loc, column_names)\n",
    "    X_loc = add_prophet_features(X_loc)\n",
    "\n",
    "    X_test_loc = add_prophet_features(X_test_loc)\n",
    "\n",
    "    X_loc = add_weather_features(X_loc)\n",
    "    X_test_loc = add_weather_features(X_test_loc)\n",
    "\n",
    "    X_loc = handle_dates(X_loc, keep_date=True)\n",
    "    X_test_loc = handle_dates(X_test_loc, keep_date=True)\n",
    "    \n",
    "    yhat1_loc, yhat2_loc, yhat3_loc, err = predict_three_days(X_loc, X_test_loc, y_loc)\n",
    "\n",
    "    errors.append(err)\n",
    "\n",
    "    bid = batch_id[loc]\n",
    "    for i, b in enumerate(bid):\n",
    "        batch_for_df[b] = [yhat1_loc[i], yhat2_loc[i], yhat3_loc[i]]\n",
    "print(\"Mean error: \", np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(batch_for_df).T\n",
    "res_df.head()\n",
    "res_df.sort_index(inplace=True)\n",
    "res_df.columns = ['1 day prediction','2 days prediction','3 days prediction']\n",
    "res_df.insert(0, 'batch_id', range(1, res_df.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
